{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg)\n",
    "\n",
    "<center>\n",
    "<h1><font size=\"+3\">NCCS Training Course Series</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Machine Learning with Scikit-Learn</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "\n",
    "- <a href=\"https://scikit-learn.org/stable/tutorial/index.html\">scikit-learn Tutorials</a>\n",
    "- <a href=\"https://medium.com/@amitg0161/sklearn-linear-regression-tutorial-with-boston-house-dataset-cde74afd460a\">Sklearn Linear Regression Tutorial with Boston House Dataset</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Scikit-Learn</font>\n",
    "\n",
    "- Scikit-learn is a free machine learning library for Python. \n",
    "- Features various algorithms like support vector machine, random forests, and k-neighbours.\n",
    "- Supports Python numerical and scientific libraries like NumPy and SciPy.\n",
    "\n",
    "![FIG_AXES](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "Image Source: scikit-learn.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements\n",
    "\n",
    "- Numpy\n",
    "- scipy\n",
    "- matplotlib\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Boston Dataset</font>\n",
    "- Contains information about different houses in Boston.\n",
    "- There are 506 samples and 13 feature variables in this dataset. \n",
    "- Maintained at Carnegie Mellon University.\n",
    "- <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\">This is a copy of UCI ML housing dataset</a>.\n",
    "\n",
    "We want to predict the value of prices of the house using the given features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys: \", boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \", boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Names: \", boston.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute Information:\n",
    "| Acronym | Description |\n",
    "| --- | --- |\n",
    "| **CRIM** |    Per capita crime rate by town |\n",
    "|**ZN** |   Proportion of residential land zoned for lots over 25,000 sq.ft. |\n",
    "| **INDUS** | Proportion of non-retail business acres per town |\n",
    "| **CHAS** |  Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "| **NOX** |  Nitric oxides concentration (parts per 10 million) |\n",
    "| **RM** |    Average number of rooms per dwelling |\n",
    "| **AGE** |   roportion of owner-occupied units built prior to 1940 |\n",
    "| **DIS** |  weighted distances to five Boston employment centres |\n",
    "| **RAD** |   index of accessibility to radial highways |\n",
    "| **TAX** |  full-value property-tax rate per \\$10,000 |\n",
    "| **PTRATIO** |  pupil-teacher ratio by town |\n",
    "| **B** |       1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town |\n",
    "| **LSTAT** |    % lower status of the population |\n",
    "| **MEDV** |    Median value of owner-occupied homes in $1000's |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Extract Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pass the data into a Pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_pd = pd.DataFrame(boston.data)\n",
    "bos_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relabel the columns using the Boston dataset feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_pd.columns = boston.feature_names\n",
    "bos_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add home prices to the Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the target data: \", boston.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_pd['PRICE']=boston.target\n",
    "bos_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Data Pre-Procesessing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Missing Values\n",
    "It is a good practice to see if there are any missing values in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values for each feature\n",
    "bos_pd.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain basic statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_pd.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exploratory Data Analysis</font>\n",
    "\n",
    "- Important step before training the model. \n",
    "- We use visualizations to understand the relationship of the target variable with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6));\n",
    "plt.hist(bos_pd['PRICE']);\n",
    "plt.title('Boston Housing Prices and Count Histogram');\n",
    "plt.xlabel('price ($1000s)');\n",
    "plt.ylabel('count');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6));\n",
    "sns.distplot(bos_pd['PRICE']);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that the values of PRICE is normally distributed with some of the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap: Two-Dimensional Graphical Representation\n",
    "- Represent the individual values that are contained in a matrix as colors.\n",
    "- Create a correlation matrix that measures the linear relationships between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9));\n",
    "correlation_matrix = bos_pd.corr().round(2);\n",
    "sns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=True);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RM** has a strong positive correlation with **PRICE** (0.7) where as **LSTAThas** a high negative correlation with **PRICE** (-0.74).\n",
    "- The features **RAD**, **TAX** have a correlation of 0.91. These feature pairs are strongly correlated to each other. This can affect the model. Same goes for the features **DIS** and **AGE** which have a correlation of -0.75.\n",
    "- The predictor variables such as **CRIM**, **INDUS**, **NOX**, **Age**, **RAD**, **TAX**, **PTRATIO**, **LSTAT** have a negative correlation on the target. Increase of any of them leads to the decrease in the price of the housing.\n",
    "- The predictor variables such as **ZN**, **RM**, **DIS**, **B** have good positive correlation with the target. Increase in any of them leads to the increase in the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in boston.feature_names:\n",
    "    plt.figure(figsize=(5, 4));\n",
    "    plt.scatter(bos_pd[feature_name], bos_pd['PRICE']);\n",
    "    plt.ylabel('Price', size=12);\n",
    "    plt.xlabel(feature_name, size=12);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prices increase as the value of RM increases linearly. There are few outliers and the data seems to be capped at 50.\n",
    "- The prices tend to decrease with an increase in LSTAT. Though it doesn’t look to be following exactly a linear line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above observations we will plot an `lmplot` between **RM** and **PRICE** to see the relationship between the two more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'RM', y = 'PRICE', data = bos_pd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Simple Linear Model</font>\n",
    "- It is difficult to visualize the multiple features.\n",
    "- We want to predict the house price with just one variable and then move to the regression with all features.\n",
    "- Because **RM** shows positive correlation with the **House Prices**, we will use **RM** for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rooms = bos_pd.RM\n",
    "y_price = bos_pd.PRICE\n",
    "\n",
    "\n",
    "X_rooms = np.array(X_rooms).reshape(-1,1)\n",
    "y_price = np.array(y_price).reshape(-1,1)\n",
    "\n",
    "print(X_rooms.shape)\n",
    "print(y_price.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing sets\n",
    "- We split the data into training and testing sets. \n",
    "- We train the model with 80% of the samples and test with the remaining 20%. \n",
    "- We do this to assess the model’s performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = \\\n",
    "             train_test_split(X_rooms, y_price, test_size = 0.2, random_state=5)\n",
    "\n",
    "print(X_train_1.shape)\n",
    "print(Y_train_1.shape)\n",
    "print(X_test_1.shape)\n",
    "print(Y_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing the model\n",
    "- We use scikit-learn’s LinearRegression to train our model on both the training and check it on the test sets.\n",
    "- We check the model performance on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1 = LinearRegression()\n",
    "reg_1.fit(X_train_1, Y_train_1)\n",
    "\n",
    "y_train_predict_1 = reg_1.predict(X_train_1)\n",
    "rmse = (np.sqrt(metrics.mean_squared_error(Y_train_1, y_train_predict_1)))\n",
    "r2 = round(reg_1.score(X_train_1, Y_train_1),2)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = reg_1.predict(X_test_1)\n",
    "rmse = (np.sqrt(metrics.mean_squared_error(Y_test_1, y_pred_1)))\n",
    "r2 = round(reg_1.score(X_test_1, Y_test_1),2)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "print(\"R^2: {}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: {:.4f}'.format(metrics.r2_score(Y_test_1, y_pred_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 45-Degree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "plt.scatter(Y_test_1, y_pred_1);\n",
    "plt.plot([0, 50], [0, 50], '--k');\n",
    "plt.axis('tight');\n",
    "plt.xlabel(\"Actual House Prices ($1000)\");\n",
    "plt.ylabel(\"Predicted House Prices: ($1000)\");\n",
    "#plt.xticks(range(0, int(max(y_test)),2));\n",
    "#plt.yticks(range(0, int(max(y_test)),2));\n",
    "plt.title(\"Actual Prices vs Predicted prices\");\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Linear Regression Model with All Variables</font>\n",
    "- We want to create a model considering all the features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bos_pd.drop('PRICE', axis = 1)\n",
    "y = bos_pd['PRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation for Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = reg_all.predict(X_train)\n",
    "rmse = (np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
    "r2 = round(reg_all.score(X_train, y_train),2)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_all.predict(X_test)\n",
    "rmse = (np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "r2 = round(reg_all.score(X_test, y_test),2)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "print(\"R^2: {}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: {:.4f}'.format(metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test - y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 45-Degree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "plt.scatter(y_test, y_pred);\n",
    "plt.plot([0, 50], [0, 50], '--k');\n",
    "plt.axis('tight');\n",
    "plt.xlabel(\"Actual House Prices ($1000)\");\n",
    "plt.ylabel(\"Predicted House Prices: ($1000)\");\n",
    "#plt.xticks(range(0, int(max(y_test)),2));\n",
    "#plt.yticks(range(0, int(max(y_test)),2));\n",
    "plt.title(\"Actual Prices vs Predicted prices\");\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMS: %r \" % np.sqrt(np.mean((y_test - y_pred) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df2 = df1.head(10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Choosing the Best Model:</font> k-Fold Cross-Validation\n",
    "\n",
    "- Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "- It is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data.\n",
    "- We use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into **k** groups\n",
    "3. For each unique group:\n",
    "       3.1 Take the group as a hold out or test data set\n",
    "       3.2 Take the remaining groups as a training data set\n",
    "       3.3 Fit a model on the training set and evaluate it on the test set\n",
    "       3.4 Retain the evaluation score and discard the model\n",
    "4. Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "How to choose **k**?\n",
    "- A poorly chosen value for **k** may result in a mis-representative idea of the skill of the model, such as a score with a high variance, or a high bias.\n",
    "- The choice of **k** is usually 5 or 10, but there is no formal rule. As **k** gets larger, the difference in size between the training set and the resampling subsets gets smaller. As this difference decreases, the bias of the technique becomes smaller.\n",
    "- A value of **k=10** is very common in the field of applied machine learning, and is recommend if you are struggling to choose a value for your dataset.\n",
    "\n",
    "Below is the visualization of a k-fold validation when k=5.\n",
    "![FIG_kFold](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "Image Source: https://scikit-learn.org/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# user variables to tune\n",
    "seed    = 9\n",
    "folds   = 10\n",
    "metric  = \"neg_mean_squared_error\"\n",
    "\n",
    "# hold different regression models in a single dictionary\n",
    "models = dict()\n",
    "models[\"Linear\"]        = LinearRegression()\n",
    "models[\"Lasso\"]         = Lasso()\n",
    "models[\"ElasticNet\"]    = ElasticNet()\n",
    "models[\"Ridge\"]         = Ridge()\n",
    "models[\"BayesianRidge\"] = BayesianRidge()\n",
    "models[\"KNN\"]           = KNeighborsRegressor()\n",
    "models[\"DecisionTree\"]  = DecisionTreeRegressor()\n",
    "models[\"SVR\"]           = SVR()\n",
    "models[\"AdaBoost\"]      = AdaBoostRegressor()\n",
    "models[\"GradientBoost\"] = GradientBoostingRegressor()\n",
    "models[\"RandomForest\"]  = RandomForestRegressor()\n",
    "models[\"ExtraTrees\"]    = ExtraTreesRegressor()\n",
    "\n",
    "# 10-fold cross validation for each model\n",
    "model_results = list()\n",
    "model_names   = list()\n",
    "for model_name in models:\n",
    "    model   = models[model_name]\n",
    "    k_fold  = KFold(n_splits=folds, random_state=seed)\n",
    "    results = cross_val_score(model, X_train, y_train, cv=k_fold, scoring=metric)\n",
    "    \n",
    "    model_results.append(results)\n",
    "    model_names.append(model_name)\n",
    "    print(\"{:>20}: {:.2f}, {:.2f}\".format(model_name, round(results.mean(), 3), \n",
    "                                  round(results.std(), 3)))\n",
    "\n",
    "# box-whisker plot to compare regression models\n",
    "figure = plt.figure();\n",
    "figure.suptitle('Regression models comparison');\n",
    "ax = figure.add_subplot(111);\n",
    "plt.boxplot(model_results);\n",
    "ax.set_xticklabels(model_names, rotation = 45, ha=\"right\");\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\");\n",
    "plt.margins(0.05, 0.1);\n",
    "#plt.savefig(\"model_mse_scores.png\")\n",
    "plt.show();\n",
    "#plt.clf()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the above comparison, we can see that `Gradient Boosting Regression` model outperforms all the other regression models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Model with Gradient Boosted Tree</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "expected = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(expected - predicted);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 45-Degree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "plt.scatter(expected, predicted)\n",
    "plt.plot([0, 50], [0, 50], '--k');\n",
    "plt.axis('tight');\n",
    "plt.xlabel('True price ($1000s)');\n",
    "plt.ylabel('Predicted price ($1000s)');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMS: %r \" % np.sqrt(np.mean((predicted - expected) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: {:.4f}'.format(metrics.r2_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Actual': expected, 'Predicted': predicted})\n",
    "df2 = df1.head(10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training deviance\n",
    "\n",
    "n_estimators = 100\n",
    "# compute test set deviance\n",
    "test_score = np.zeros((n_estimators,), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(clf.staged_predict(X_test)):\n",
    "    test_score[i] = clf.loss_(expected, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.subplot(1, 1, 1);\n",
    "plt.title('Deviance');\n",
    "plt.plot(np.arange(n_estimators) + 1, clf.train_score_, 'b-',\n",
    "         label='Training Set Deviance');\n",
    "plt.plot(np.arange(n_estimators) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance');\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel('Boosting Iterations');\n",
    "plt.ylabel('Deviance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "- Once we have a trained model, we can understand feature importance (or variable importance) of the dataset which tells us how important each feature is, to predict the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model's feature importance\n",
    "feature_importance = clf.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos        = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center');\n",
    "plt.yticks(pos, boston.feature_names[sorted_idx]);\n",
    "plt.xlabel('Relative Importance');\n",
    "plt.title('Variable Importance');\n",
    "#plt.savefig(\"feature_importance.png\");\n",
    "#plt.clf();\n",
    "#plt.close();"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
