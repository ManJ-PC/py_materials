{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"white\">.</font> | <font color=\"white\">.</font> | <font color=\"white\">.</font>\n",
    "-- | -- | --\n",
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg) | <h1><font size=\"+3\">ASTG Python Courses</font></h1> | ![NASA](https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png)\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Introduction to Tensorflow</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Reference\n",
    "\n",
    "- <a href=\"https://www.mygreatlearning.com/blog/what-is-tensorflow-machine-learning-library-explained/\">What is TensorFlow? The Machine Learning Library Explained</a>\n",
    "- <a href=\"https://www.tensorflow.org/tutorials/keras/regression\">Basic regression: Predict fuel efficiency</a>\n",
    "- <a href=\"https://stackabuse.com/tensorflow-2-0-solving-classification-and-regression-problems/\">Tensorflow 2.0: Solving Classification and Regression Problems</a>\n",
    "- <a href=\"https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial\">Getting Started with TensorFlow: A Machine Learning Tutorial</a>\n",
    "- <a href=\"https://sebastianraschka.com/faq/docs/tensorflow-vs-scikitlearn.html\">What is the main difference between TensorFlow and scikit-learn?</a>\n",
    "- <a href=\"https://adventuresinmachinelearning.com/python-tensorflow-tutorial/\">Python TensorFlow Tutorial – Build a Neural Network</a>\n",
    "- <a href=\"https://steadforce.com/en/first-steps-tensorflow-part-3/\">A simple neural network with TensorFlow</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">What is TensorFlow?</font>\n",
    "- TensorFlow is an open-source library for numerical computation and large-scale machine learning that ease `Google Brain TensorFlow`, the process of acquiring data, training models, serving predictions, and refining future results.\n",
    "- Tensorflow bundles together Machine Learning and Deep Learning models and algorithms.\n",
    "- The name `TensorFlow` is derived from the operations which neural networks perform on multidimensional data arrays or `tensors`! It’s literally a flow of tensors.\n",
    "- It uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.\n",
    "- TensorFlow can train and run neural networks for applications such as handwritten digit classification, image recognition, word embeddings, sequence-to-sequence models for machine translation, natural language processing, and partial differential equations based simulations.\n",
    "- TensorFlow supports both CPUs and GPUs computing devices.\n",
    "\n",
    "#### How Does it Work?\n",
    "\n",
    "- TensorFlow allows developers to create a graph of computations to perform. \n",
    "- Nodes in the graph represent mathematical operations (add, substract, multiply, etc.).\n",
    "- Connections (edges) represent data which usually are multidimensional data arrays or tensors, that are communicated between these edges.\n",
    "- Once you have the graph, the execution can be enabled either on regular CPUs or GPUs, or distributed across several of them so that the processing becomes much faster.\n",
    "\n",
    "#### First Example of TensorFlow Graph\n",
    "\n",
    "Consider the expression:\n",
    "<center>\n",
    "    a = (b + c) * (c + 2)\n",
    "</center>\n",
    "We can break this down into:\n",
    "<center>\n",
    "    d = b + c\n",
    "    \n",
    "    e = c + 2\n",
    "    \n",
    "    a = d * e\n",
    "</center>\n",
    "Now we can represent these operations graphically as:\n",
    "\n",
    "![fig_gr1](https://i1.wp.com/adventuresinmachinelearning.com/wp-content/uploads/2017/03/Simple-graph-example.png)\n",
    "Image Source: adventuresinmachinelearning.com\n",
    "\n",
    "Note that the operations `d = b + c` and `e = c + 2` can be performed in parallel: potential of distributing such calcultions across CPUs and GPUs. \n",
    "\n",
    "**Second Example of TensorFlow Graph**\n",
    "\n",
    "The graph below shows the computational graph of a three-layer neural network.\n",
    "The animated data flows between different nodes in the graph are tensors which are multi-dimensional data arrays. \n",
    "\n",
    "\n",
    "![fig_gr2](https://i1.wp.com/adventuresinmachinelearning.com/wp-content/uploads/2017/03/TensorFlow-data-flow-graph.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Main Steps of a ML Program</font>\n",
    "    \n",
    "![FIG_AXES](https://www.altudo.co/-/media/altudo/images/resources/blogs/5-steps-to-define-ml-flow-to-deliver-custom-user-experience/2.ashx?la=en&hash=0A8E8BEC05A4C64C37908FB87757285E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Numpy version:      {np.__version__}\")\n",
    "print(f\"Pandas version:     {pd.__version__}\")\n",
    "print(f\"Seaborn version:    {sns.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Problem Statement</font>\n",
    "\n",
    "We consider the function: <br>\n",
    "$$\n",
    "f(x,y) = (1-(x^2 + y^3))e^{-\\frac{1}{2}(x^2 + y^2)}\n",
    "$$\n",
    "<br>\n",
    "defined in the domain $D=[-3,3] \\times [-3,3]$.\n",
    "<OL>\n",
    "<LI> We randomnly select $n$ points in the domain $D$ and compute the function on those points to create a (training) dataset containing $n$ pairs points/values.\n",
    "<LI> We use the dataset for training a ML algorithm.\n",
    "<LI> We generate a uniform set of points (testing set) in $D$ to test the algorithm.\n",
    "</OL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Generating the Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff(x,y):\n",
    "    return (1-(x**2+y**3))*np.exp(-(x**2+y**2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = 2\n",
    "nx = 30\n",
    "ny = 30\n",
    "num_points = nx * ny\n",
    "\n",
    "# Boundary of the domain\n",
    "a_min = -3.0\n",
    "a_max = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Generate dataset for training</font>\n",
    "- The grid points are randomly generated over the domain\n",
    "- The arrays are 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.uniform(a_min, a_max, (num_points, num_dims))\n",
    "y_train = ff(X_train[:,0], X_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Add noise in the training targets</font>\n",
    "\n",
    "- The function `ff` is smooth.\n",
    "- We want to add noise to the targets.\n",
    "- We consider as noise a Gaussian normal distribution with `noise_mean` as mean and `noise_std` as standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_mean = 0.0\n",
    "noise_std  = 1.0e-2\n",
    "noise = np.random.normal(noise_mean, noise_std, num_points)\n",
    "y_train = y_train + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Generate dataset for validation</font>\n",
    "- The grid points are uniformly distributed over the domain\n",
    "- The arrays are 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(a_min, a_max, nx)\n",
    "y = np.linspace(a_min, a_max, ny)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "X_valid = np.zeros((num_points, num_dims))\n",
    "X_valid[:, 0] = xx.flatten()\n",
    "X_valid[:, 1] = yy.flatten()\n",
    "y_valid = ff(X_valid[:,0], X_valid[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Data Gathering and Basic Analyses</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({\"x0\": X_train[:,0], \"x1\": X_train[:,1], \n",
    "                           \"TargetValues\": y_train[:]})\n",
    "print(train_data.head(5))                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data to be used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data  = pd.DataFrame({\"x0\": X_valid[:,0], \"x1\": X_valid[:,1], \n",
    "                            \"TargetValues\": y_valid[:]})\n",
    "print(valid_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the data to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedee = plt.figure().gca(projection='3d');\n",
    "threedee.scatter(train_data['x0'], train_data['x1'], \n",
    "                 train_data['TargetValues']);\n",
    "threedee.set_xlabel('x');\n",
    "threedee.set_ylabel('y');\n",
    "threedee.set_zlabel('f(x,y)');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x=train_data['x0'], y=train_data['x1'], \n",
    "            cmap=\"Blues\", shade=True, bw_adjust=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the joint distribution of the columns from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_data.drop(columns=[\"TargetValues\"]), diag_kind=\"kde\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do something similar for the data used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(valid_data.drop(columns=[\"TargetValues\"]), diag_kind=\"kde\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the overall statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_data.describe()\n",
    "train_stats.pop(\"TargetValues\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split features from labels\n",
    "- Separate the target value, or `label`, from the features.\n",
    "- This `label` is the value that you will train the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data.pop('TargetValues')\n",
    "valid_labels = valid_data.pop('TargetValues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Normailized the Data</font>\n",
    "\n",
    "- In general, variables may not be a similar scale. High values would gain more importance in any distance-based calculations. \n",
    "- It is good practice to normalize features that use different scales and ranges. \n",
    "- Although the model might converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    \"\"\"\n",
    "       Normalize the data\n",
    "    \"\"\"\n",
    "    return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize the data that will be used to train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_train_data = normalize_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also need to normalize the validation dataset by projecting it into the same distribution that the model has been trained on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_valid_data = normalize_data(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**The same normalization will have to be applied to any other data used in this model.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Build the Model</font>\n",
    "\n",
    "#### Instantiate a sequential model using `keras`\n",
    "- `keras` is TensorFlow's high-level API for building and training deep learning models. It's used for fast prototyping, state-of-the-art research, and production.\n",
    "- <font color=\"red\">The sequential model is the simplest model to use, especially when getting started.</font>\n",
    "- It involves defining a Sequential class and adding layers to the model one by one in a linear manner, from input to output.\n",
    "- The model needs to know what input shape (`input_shape`) it should expect. The first layer of the `Sequential` model needs to receive the information.\n",
    "\n",
    "In the model below:\n",
    "\n",
    "- The model expects rows of data with `num_shape` variables (the `input_shape=num_shape` argument)\n",
    "- The first hidden layer has 16 nodes and uses the `relu` activation function.\n",
    "- The second hidden layer has 16 nodes and uses the `relu` activation function.\n",
    "- The output layer has one node and uses no activation function.\n",
    "\n",
    "The rectified linear activation function (`relu`) is a piecewise linear function that will output the input directly if is positive, otherwise, it will output zero. \n",
    "- Because rectified linear units are nearly linear, they preserve many of the properties that make linear models easy to optimize with gradient-based methods. They also preserve many of the properties that make linear models generalize well.\n",
    "- It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shape = len(train_data.keys())\n",
    "num_nodes = 16\n",
    "\n",
    "model = keras.Sequential([\n",
    "             layers.Dense(num_nodes, activation=tf.nn.relu, \n",
    "                          input_shape=[num_shape]),\n",
    "             layers.Dense(num_nodes, activation=tf.nn.relu),\n",
    "             layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model creation can also be written as:\n",
    "\n",
    "```python\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(num_nodes, activation=tf.nn.relu, \n",
    "                       input_shape=[num_shape]))\n",
    "model.add(layers.Dense(num_nodes, activation=tf.nn.relu))\n",
    "model.add(layers.Dense(1))\n",
    "```\n",
    "\n",
    "Dense layers represent a function that maps the input tensor `x` to an output tensor `y` via the equation `y = Ax + b` where `A` (the kernel) and `b` (the bias) are parameters of the dense layer.\n",
    "\n",
    "![nn](https://git.mysmce.com/astg/training/py_materials/-/blob/master/machine_learning/tensorflow_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "- Once you have specified the architecture of the network, you need to specify the method for back-propagation by choosing an optimizer and specify the loss.\n",
    "- Compiling the model uses the efficient numerical libraries (Theano or TensorFlow) in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required to provide a loss function and an optimizer: \n",
    "- We are asking the network to use the `rmsprop` optimizer to change weights in such a way that the loss `mse` (mean squared error) is minimized at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the model\n",
    "\n",
    "`model.summary()` is a useful method if you want to get an overview of your model and see the total number of parameters.\n",
    "It prints:\n",
    "\n",
    "- Name and type of all layers in the model.\n",
    "- Output shape for each layer.\n",
    "- Number of weight parameters of each layer.\n",
    "-  If the model has general topology, the inputs each layer receives\n",
    "- The total number of trainable and non-trainable parameters of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable params: {:,}'.format(trainable_count))\n",
    "print('Non-trainable params: {:,}'.format(non_trainable_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Let](https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889):\n",
    "\n",
    "- **i**: input size (2 in this case)\n",
    "- **h**: size of hidden layers (16, 16 here)\n",
    "- **o**: output size (1 in this case)\n",
    "\n",
    "We have:\n",
    "\n",
    "    num_params = connections between layers + biases in every layer\n",
    "               = (i×h + h×o) + (h+o)\n",
    "               = (2x16 + 16x16 + 16*1) + (16 + 16 + 1)\n",
    "               = (2x16 + 16) + (16x16 + 16) + (16x1 + 1)\n",
    "               = 48 + 272 + 17\n",
    "               = 337\n",
    "               \n",
    "   input = **Input**((None, 2))\n",
    "   <br>\n",
    "   dense = **Dense**(16)(input)\n",
    "      <br>\n",
    "   dense = **Dense**(16)(dense)\n",
    "    <br>\n",
    "  output = **Dense**(1)(dense)\n",
    "   <br>\n",
    "   model = Model(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try the model\n",
    "\n",
    "10 samples from the training data and call `model.predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = normed_train_data[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "print(example_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be working, and it produces a result of the expected shape and type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Train the Model</font>\n",
    "\n",
    "Training occurs over epochs and each epoch is split into batches.\n",
    "\n",
    "- **Epoch**: One pass through all of the rows in the training dataset.\n",
    "- **Batch**: One or more samples considered by the model within an epoch before updating the internal model parameters (weights).\n",
    "- One epoch is comprised of one or more batches, based on the chosen batch size and the model is fit for many epochs. \n",
    "- The model is \"fit\" to the training data using the `fit` method. We also specify the `batch_size` and the maximum number of `epochs` we want training to go on.\n",
    "- The callback function is applied at given stages of the training procedure. We use it to get a view on internal states and statistics of the model during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for 1000 epochs, and record the training and validation accuracy in the history object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training progress by printing a \n",
    "# single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "          if epoch % 100 == 0: \n",
    "             print('')\n",
    "          print('.', end='')\n",
    "\n",
    "# How many times we go through the entire dataset\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(normed_train_data, train_labels,    \n",
    "                    epochs=EPOCHS, verbose=1, \n",
    "                    callbacks=[PrintDot()])\n",
    "#epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the model's training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stats stored in the history object.\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(history.history.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [Target]')\n",
    "    plt.plot(hist['epoch'], hist[keys[1]], label='Train Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([min(hist[keys[1]]) ,max(hist[keys[1]])])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$Target^2$]')\n",
    "    plt.plot(hist['epoch'], hist[keys[2]], label='Train Error')            \n",
    "    plt.legend()\n",
    "    plt.ylim([0,max(hist[keys[2]])])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Evaluate the Model on Test Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(normed_valid_data, valid_labels, verbose=1)\n",
    "#print(\"Testing set Mean Abs Error: {} \".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predictions = model.predict(normed_valid_data).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the 45-degree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(valid_labels, valid_predictions);\n",
    "plt.xlabel('True Values');\n",
    "plt.ylabel('Predictions');\n",
    "plt.axis('equal');\n",
    "plt.axis('square');\n",
    "plt.xlim([0,plt.xlim()[1]]);\n",
    "plt.ylim([0,plt.ylim()[1]]);\n",
    "_ = plt.plot([-100, 100], [-100, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(valid_predictions - valid_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Function Using Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedee = plt.figure().gca(projection='3d');\n",
    "threedee.scatter(valid_data['x0'], valid_data['x1'], valid_predictions);\n",
    "threedee.set_xlabel('x');\n",
    "threedee.set_ylabel('y');\n",
    "threedee.set_zlabel('f(x,y)');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Exercise</font>\n",
    "\n",
    "Consider the 2D problem presented here.\n",
    "- Create a dataset of 1000 randomly selected points (in the domain) and their associated targets.\n",
    "- Randomly choose 80% of the data for training and the remaining for testing\n",
    "- Create your ML model and test it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
