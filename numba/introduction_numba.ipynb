{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg)\n",
    "\n",
    "<center>\n",
    "<h1><font size=\"+3\">GSFC Python Bootcamp</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<CENTER>\n",
    "<H1 style=\"color:red\">\n",
    "Introduction to Numba\n",
    "</H1>\n",
    "</CENTER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I’m becoming more and more convinced that Numba is the future of fast scientific computing in Python. \n",
    ">\n",
    "> – Jake Vanderplas, 2013-06-15\n",
    ">\n",
    "> http://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/\n",
    "\n",
    "\n",
    "![fig_numba](https://thedatafrog.com/static/blog/images/2019/07/python_fast.0d88afcb4f8a.png)\n",
    "Image Source: Lison Bernet 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>What will be Covered?</font>\n",
    "\n",
    "* What is Numba?\n",
    "* How Does Numba Work?\n",
    "* Numpy and Numba\n",
    "* How to Use Numba?\n",
    "* Parallelization with Numba\n",
    "* Numba and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reference Documents</font>\n",
    "- <a href=\"http://numba.pydata.org/\">Numba: A High Performance Python Compiler</a>\n",
    "- <a href=\"https://examples.dask.org/applications/stencils-with-numba.html\">Stencil Computations with Numba</a>\n",
    "- <a href=\"http://deepdata.com.pl/numba.html\">Python on steroids - speeding up calculations with numba</a>\n",
    "- <a href=\"https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/COMPASS_gpu_intro.ipynb\">Introduction to GPU programming with Numba</a>\n",
    "- <a href=\"https://www.deeplearningwizard.com/deep_learning/production_pytorch/speed_optimization_basics_numba/\">Speed Optimization Basics: Numba</a>\n",
    "- <a href=\"https://murillogroupmsu.com/numba-versus-c/\">High-Performance Python: Why?</a>\n",
    "- <a href=\"https://flothesof.github.io/optimizing-python-code-numpy-cython-pythran-numba.html\">Optimizing your code with NumPy, Cython, pythran and numba </a>\n",
    "- <a href=\"https://www.polymorphe.org/index.php/looping-over-pandas-data-mkd\">Looping over Pandas data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>What is Numba?</font>\n",
    "\n",
    "> Numba is an open-source JIT compiler that translates a subset of Python and NumPy into fast machine code using `LLVM`, via the llvmlite Python package. It offers a range of options for parallelising Python code for CPUs and GPUs, often with only minor code changes. \n",
    ">\n",
    ">Wikipedia\n",
    "\n",
    "- Numba is a Python open source package that was originally developed by Continuum Analytics.\n",
    "- The core application area are math-heavy and array-oriented functions, which are in native Python pretty slow.\n",
    "- It accelerates Python code (numerical functions) for both CPU and GPU:\n",
    "   - **Function Compiler**: Numba compiles Python functions, not whole applications or parts of it. It is a Python module meant to improve the performance of functions with the goal of achieving a speed comparable to `C`.\n",
    "   - **Just-in-time**: (Dynamic translation) Numba translates the bytecode (intermediate code more abstract than the machine code) to machine code immediately before its execution to improve the execution speed.\n",
    "   - **Numerically-focused**: Numba is focused on numerical data, such as int, float, complex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>How Does Numba Work?</font>\n",
    "\n",
    "- Assume that you have a function `do_math` that is decorated with the Numba `@jit` decorator. \n",
    "- Compilation will be deferred until the first function execution. \n",
    "- Numba will infer the argument types at call time, and generate optimized code based on this information. \n",
    "- Numba will also be able to compile separate specializations depending on the input types. \n",
    "- The diagram below, shows all the steps carried out by Numba to execute `do_math`. \n",
    "\n",
    "![fig_numba](https://miro.medium.com/max/1400/1*S0S4QUjR-BsdTICtT9797Q.png)\n",
    "Image Source: Continuum Analytics\n",
    "\n",
    "- **IR**: Intermediate Representations\n",
    "- **Bytecode Analysis**: Intermediate code more abstract than machine code\n",
    "- **LLVM**: Low Level Virtual Machine, infrastructure to develop compilers\n",
    "- **NVVM**: It is an IR compiler based on LLVM, it is designed to represent GPU kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Numpy and Numba</font>\n",
    "- One objective of Numba is having a seamless integration with NumPy. \n",
    "- Numba excels at generating code that executes on top of NumPy arrays.\n",
    "- NumPy support in Numba comes in many forms:\n",
    "    1. Numba understands calls to NumPy ufuncs (universal functions: there are over 60 of them) and is able to generate equivalent native code for many of them.\n",
    "    2. NumPy arrays are directly supported in Numba.\n",
    "    3. Numba is able to generate ufuncs and gufuncs (generalized universal functions). This means that it is possible to implement ufuncs and gufuncs within Python, getting speeds comparable to that of ufuncs/gufuncs implemented in C extension modules using the NumPy C API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Usage</font>\n",
    "- Numba provides several utilities for code generation.\n",
    "- Its central feature is the `numba.jit()` decorator. \n",
    "- Using this decorator, you can mark a function for optimization by Numba’s JIT compiler. - - - Various invocation modes trigger differing compilation options and behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from numba import njit\n",
    "from numba import prange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Consider the function that multiplies two `nxn` matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matrix_multiplication(A, B):\n",
    "    \"\"\"\n",
    "        Multiply matrices A and B using a loop\n",
    "    \"\"\"\n",
    "    n = len(A[0])\n",
    "    C = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                C[i, j] += A[i, k]*B[k, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "A = np.random.rand(N, N)\n",
    "B = np.random.rand(N, N)\n",
    "D = np.random.rand(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit matrix_multiplication(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now decorate the above multiplication with `jit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def matrix_multiplication_numba(A, B):\n",
    "    \"\"\"\n",
    "        Multiply matrices A and B using a loop\n",
    "    \"\"\"\n",
    "    n = len(A[0])\n",
    "    C = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                C[i, j] += A[i, k]*B[k, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit matrix_multiplication_numba(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measuring the Performance of Numba**\n",
    "\n",
    "- Once the compilation has taken place, Numba runs the machine code version of your function. \n",
    "- If it is called again with same argument types, it can reuse the cached version instead of having to compile again.\n",
    "- A common mistake when measuring performance is not accounting for the above behaviour and to time code once with a simple timer that includes the time taken to compile your function in the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_1 = time.time()\n",
    "matrix_multiplication_numba(A, B)\n",
    "end_1 = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end_1 - start_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_2 = time.time()\n",
    "matrix_multiplication_numba(A, B)\n",
    "end_2 = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end_2 - start_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation Options\n",
    "A number of keyword-only arguments can be passed to the `@jit` decorator:\n",
    "1. `nopython`: Numba has two compilation modes:\n",
    "     - nopython mode (`nopython=True`): Compile the decorated function so that it will run entirely without the involvement of the Python interpreter. It produces much faster code, but has limitations that can force Numba to fall back to the object mode. Note that <font color=\"red\">**`@njit`**</font> is an alias for <font color=\"red\">**`@jit(nopython=True)`**</font>.\n",
    "     - object mode: In this mode Numba will identify loops that it can compile and compile those into functions that run in machine code, and it will run the rest of the code in the interpreter. For best performance avoid using this mode!\n",
    "2. `nogil`: \n",
    "     - Whenever Numba optimizes Python code to native code that only works on native types and variables (rather than Python objects), it is not necessary anymore to hold Python’s global interpreter lock (GIL). \n",
    "     - Numba will release the GIL when entering such a compiled function if you passed `nogil=True`.\n",
    "     - When using `nogil=True`, you need to be wary of the usual pitfalls of multi-threaded programming (consistency, synchronization, race conditions, etc.).\n",
    "3. `cache`:\n",
    "     - To avoid compilation times each time you invoke a Python program, you can instruct Numba to write the result of function compilation into a file-based cache. \n",
    "     - This is done by passing `cache=True`.\n",
    "4. `parallel`: \n",
    "     - Enables automatic parallelization (and related optimizations) for operations in the function known to have parallel semantics.\n",
    "     - This feature is enabled by passing `parallel=True` and must be used in conjunction with `nopython=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastmath\n",
    "- In certain classes of applications strict IEEE 754 compliance is less important. \n",
    "- It is possible to relax some numerical rigour with view of gaining additional performance. \n",
    "- The way to achieve this behaviour in Numba is through the use of the `fastmath` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=False)\n",
    "def do_sum(A):\n",
    "    acc = 0.\n",
    "    # without fastmath, this loop must accumulate in strict order\n",
    "    for x in A:\n",
    "        acc += np.sqrt(x)\n",
    "    return acc\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def do_sum_fast(A):\n",
    "    acc = 0.\n",
    "    # with fastmath, the reduction can be vectorized as floating point\n",
    "    # reassociation is permitted.\n",
    "    for x in A:\n",
    "        acc += np.sqrt(x)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_do_sum = %timeit -o acc1 = do_sum(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_do_sum_fast = %timeit  -o acc2 = do_sum_fast(D)\n",
    "print(time_do_sum.best / time_do_sum_fast.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Parallelization </font>\n",
    "\n",
    "- The setting `parallel=True` in `jit()` enables a Numba transformation pass that attempts to automatically parallelize and perform other optimizations on (part of) a function.\n",
    "- A user program may contain operations (for instance adding a scalar value to an array) that are known to have parallel semantics.\n",
    "- Each operation could be parallelized individually but that might light to poor performance due to poor cache behavior.\n",
    "- Numba uses instead auto-parallelization where it identifies all operations with parallel sementics and fuses adjacent ones together, to form one or more kernels that are automatically run in parallel.\n",
    "- The process is fully automated without modifications to the user program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Parallel Loops\n",
    "\n",
    "- Numba parallel execution also has support for explicit parallel loop declaration similar to that in OpenMP. \n",
    "- To indicate that a loop should be executed in parallel the `numba.prange` function should be used.\n",
    "- This function behaves like Python `range` and if `parallel=True` is not set it acts simply as an alias of `range`. \n",
    "- Loops induced with `prange` can be used for embarrassingly parallel computation and also reductions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def matrix_multiplication_numba2(A, B):\n",
    "    \"\"\"\n",
    "        Multiply matrices A and B using a loop\n",
    "    \"\"\"\n",
    "    n = len(A[0])\n",
    "    C = np.zeros((n, n))\n",
    "    for i in prange(n):\n",
    "        for j in prange(n):\n",
    "            for k in prange(n):\n",
    "                C[i, j] += A[i, k]*B[k, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit matrix_multiplication_numba2(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics\n",
    "- We can produce diagnostic information about the transforms undertaken in automatically parallelizing the decorated code. \n",
    "- This information can be accessed in two ways:\n",
    "     1. Setting the environment variable: `NUMBA_PARALLEL_DIAGNOSTICS`\n",
    "     2. Calling the function `parallel_diagnostics()`\n",
    "- The level of verbosity in the diagnostic information is controlled by an integer argument of value between 1 and 4 inclusive, 1 being the least verbose and 4 the most.\n",
    "\n",
    "For additional information, consult the webpage: <a href=\"http://numba.pydata.org/numba-doc/latest/user/parallel.html\"> http://numba.pydata.org/numba-doc/latest/user/parallel.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def test(x):\n",
    "    n = x.shape[0]\n",
    "    a = np.sin(x)\n",
    "    b = np.cos(a * a)\n",
    "    acc = 0\n",
    "    for i in prange(n - 2):\n",
    "        for j in prange(n - 1):\n",
    "            acc += b[i] + b[j + 1]\n",
    "    return acc\n",
    "\n",
    "test(np.arange(10))\n",
    "\n",
    "test.parallel_diagnostics(level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Things to Consider when Using Numba</font>\n",
    "\n",
    "- Numba allows its behaviour to be changed through the use of <a href=\"http://numba.pydata.org/numba-doc/latest/reference/envvars.html\">environment variables</a>. Unless otherwise mentioned, those variables have integer values and default to zero.\n",
    "- Not all the <a href=\"http://numba.pydata.org/numba-doc/latest/reference/pysupported.html\">Python feautures</a> are supported by Numba.\n",
    "- While Python has arbitrary-sized integers, integers in Numba-compiled functions get a fixed size through type inference (usually, the size of a machine integer). This means that arithmetic operations can wrapround or produce undefined results or overflow.\n",
    "- Numba may or may not copy global variables referenced inside a compiled function. Small global arrays are copied for potential compiler optimization with immutability assumption. However, large global arrays are not copied to conserve memory. The definition of “small” and “large” may change.\n",
    "- Numba does not work with recusive function.\n",
    "- For some operations, Numba may use a different algorithm than Python or Numpy. The results may not be bit-by-bit compatible. The difference should generally be small and within reasonable expectations. However, small accumulated differences might produce large differences at the end, especially if a divergent function is involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Numba and Pandas</font>\n",
    "\n",
    "- Pandas is built on top of Numpy.\n",
    "- Pandas offers flexibility in manipulating data but not necessary speed.\n",
    "- This flexibility allows the creation of built-in function.\n",
    "- Crude looping (over DataFrame rows for instance) in Pandas does not take advantage of any built-in optimizations, making it extremely inefficient.\n",
    "- Using vectorized Pandas built-in functions (acting on Pandas Series) is almost always preferable to accomplishing similar ends with custom-written looping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "An exponential moving average (EMA) is a first-order infinite impulse response filter that applies weighting factors which decrease exponentially. The EMA for a series Y may be calculated recursively:\n",
    "\n",
    "\n",
    "$$S_{t}=\\begin{cases}Y_{1},&t=1\\\\\\alpha \\cdot Y_{t}+(1-\\alpha )\\cdot S_{t-1},&t>1\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def ewm(arr, alpha):\n",
    "    \"\"\"\n",
    "    Calculate the EMA of an array arr\n",
    "    :param arr: numpy array of floats\n",
    "    :param alpha: float between 0 and 1\n",
    "    :return: numpy array of floats\n",
    "    \"\"\"\n",
    "    # initialise ewm_arr\n",
    "    ewm_arr = np.zeros_like(arr)\n",
    "    ewm_arr[0] = arr[0]\n",
    "    for t in prange(1,arr.shape[0]):\n",
    "        ewm_arr[t] = alpha*arr[t] + (1 - alpha)*ewm_arr[t-1]\n",
    "\n",
    "    return ewm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "a = np.random.random(N)\n",
    "df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.ewm(com=0.5, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ewm(a, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Could we claim that Numpy/Numba is faster than Pandas?**\n",
    "\n",
    "- Not necessarily!\n",
    "- Over time, Pandas relies more on  Cython operations.\n",
    "- In Pandas 1.0 (and newer versions) Pandas’ `apply()` method (applies a function along a specific axis of a DataFrame) can make use of Numba (if installed) instead of cython and be faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
