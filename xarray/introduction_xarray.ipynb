{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"white\">.</font> | <font color=\"white\">.</font> | <font color=\"white\">.</font>\n",
    "-- | -- | --\n",
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg) | <h1><font size=\"+3\">ASTG Python Courses</font></h1> | ![NASA](https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png)\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1><font color=\"red\" size=\"+3\">Introduction to Xarray</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Useful References</font>\n",
    "- <a href=\"http://xarray.pydata.org/en/stable/\"> xarray</a>\n",
    "- <a href=\"https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\"> xarray: N-D labeled arrays and datasets in Python</a>\n",
    "- <a href=\"https://nbviewer.jupyter.org/github/mccrayc/tutorials/blob/master/2_reanalysis/CFSR_Data_Tutorial.ipynb\">Importing and mapping reanalysis data with xarray and cartopy</a>\n",
    "- <a href=\"https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\">xarray: N-D labeled Arrays and Datasets in Python</a>\n",
    "- <a href=\"https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/use-netcdf-in-python-xarray/\">How to Open and Process NetCDF 4 Data Format in Open Source Python</a>\n",
    "- <a href=\"https://cbrownley.wordpress.com/tag/xarray/\">Visualizing Global Land Temperatures in Python with scrapy, xarray, and cartopy</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig_logo](http://xarray.pydata.org/en/stable/_static/dataset-diagram-logo.png)\n",
    "Image Source: xarray.pydata.org\n",
    "\n",
    "## <font color=\"red\">What is Xarray?</font>\n",
    "+ `Xarray` is an open source project and Python package that makes working with labelled multi-dimensional arrays simple and efficient.\n",
    "+ Introduces labels in the form of dimensions, coordinates and attributes on top of raw `NumPy`-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. \n",
    "+ Is inspired by and borrows heavily from `Pandas`.\n",
    "+ Builds on top of, and seamlessly interoperates with, the core scientific Python packages, such as NumPy, SciPy, Matplotlib, and Pandas\n",
    "+ Is particularly tailored to working with `netCDF` files and integrates tightly with `Dask` for parallel computing.\n",
    "\n",
    "## <font color=\"red\">Implementation and architecture</font>\n",
    "- NetCDF forms the basis of the Xarray data model and provides a natural and portable serialization format. \n",
    "- Xarray features two main data structures: \n",
    "     - **DataArray** xarray’s implementation of a labeled, multi-dimensional array. It has several key properties:\n",
    "          - *data*: N-dimensional array (NumPy or dask) holding the array's values,\n",
    "          - *coords*: dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings),\n",
    "          - *dims*: dimension names for each axis [e.g., (‘time’, ‘latitude’, ‘longitude’)],\n",
    "          - *attrs*: OrderedDict holding arbitrary metadata (e.g. units or descriptions), and\n",
    "          - *name*: an arbitrary name for the array.\n",
    "     - **Dataset**: xarray’s multi-dimensional equivalent of a DataFrame. It is a dict-like container of labeled arrays (DataArrays) with aligned dimensions. It is designed as an in-memory representation of a netCDF dataset. In addition to the dict-like interface of the dataset itself, which can be used to access any DataArray in a Dataset, datasets have four key properties:\n",
    "          - *data_vars*: OrderedDict of DataArray objects corresponding to data variables,\n",
    "          - *coords*: OrderedDict of DataArray objects intended to label points used in data_vars (e.g., 1-dimensional arrays of numbers, datetime objects or strings),\n",
    "          - *dims*: dictionary mapping from dimension names to the fixed length of each dimension (e.g., {‘x’: 6, ‘y’: 6, ‘time’: 8}), and\n",
    "          - *attrs*: OrderedDict to hold arbitrary metadata pertaining to the dataset.\n",
    "\n",
    "![fig_structure](https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/jors-5-148-g2.png)\n",
    "Image Source: openresearchsoftware.metajnl.com\n",
    "\n",
    "\n",
    "## <font color=\"red\">Core xarray Features</font>\n",
    "\n",
    "- <u>*Serialization and I/O*</u>: xarray supports direct serialization and I/O to several file formats including pickle, netCDF, OPeNDAP (read-only), GRIB1/2 (read-only), and HDF by integrating with third-party libraries.\n",
    "- <u>*Metadata*</u>: Keep track of arbitrary metadata in the form of a Python dictionary. `x.attrs`.\n",
    "- <u>*Label-based indexing*</u>: Similarly to Pandas objects, xarray objects support both integer- and label-based lookups along each dimension. However, xarray objects also have named dimensions, so you can optionally use dimension names instead of relying on the positional ordering of dimensions. `x.loc['2014-01-01']` or `x.sel(time='2014-01-01')`\n",
    "- <u>*Arithmetic*</u>: arithmetic between xarray objects vectorizes based on dimension names, automatically looping (broadcasting) over each distinct dimension. This eliminates the need to insert dummy dimensions of size one to facilitate broadcasting, a common pattern with NumPy.\n",
    "- <u>*Aggregation*</u>: calculation of statistics (e.g. sum) along a dimension of an xarray object can be done by dimension name instead of an integer axis number. `x.sum('time')`\n",
    "- <u>*Plotting*</u>: Plotting functionality is a thin wrapper around Matplotlib. The syntax and function names from Matplotlib are used whenever possible, resulting in a seamless transition between the two.\n",
    "- <u>*Missing Data*</u>: Are smoothly handled in all operations, including arithmetic, alignment and aggregation.\n",
    "- <u>*Interactivity with Pandas*</u>: xarray objects seamlessly to convert to and from pandas objects to interact with the rest of the PyData ecosystem.\n",
    "- <u>*Out-of-core computation*</u>: xarray’s data structures can be backed by dask to support parallel and streaming computation on data that does not fit into memory, up to 100s of GB or TBs in size. \n",
    "- <u>*Alignment*</u>: Support of  database-like join operations for combining xarray objects along common coordinates.\n",
    "- <u>*Split-apply-combine*</u>: xarray includes N-dimensional grouped operations implementing the split-apply-combine strategy. `x.groupby('time.dayofyear').mean()`\n",
    "- <u>*Resampling and rolling window operations*</u>: Utilizing the efficient resampling methods from Pandas and rolling window operations from Bottleneck, xarray offers a robust set of resampling and rolling window operations along a single dimension.\n",
    "\n",
    "## <font color=\"red\">Supported File Types</font>\n",
    "\n",
    "`Xarray`  supports direct serialization and IO to several file formats:\n",
    "\n",
    "- Pickle\n",
    "- netCDF 3/4 format (recommended)\n",
    "- RaterIO\n",
    "- Zarr: a Python package providing an implementation of chunked, compressed, N-dimensional arrays. Zarr has the ability to store arrays in a range of ways, including in memory, in files, and in cloud-based object storage such as Amazon S3 and Google Cloud Storage. \n",
    "- GRIB format: thereading of GRIB files is done using the ECMWF `cgrib` Python driver (`engine='cfgrib'` as argument of `open_dataset`).\n",
    "- Xarray can read GRIB, HDF4 and other file formats supported by PyNIO (`engine='pynio'` as argument of `open_dataset`).\n",
    "- Xarray can also read HDF5 files (using netCDF4 first) but can only access variables within groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color='red'> Only run the following cell if you are on Google Colab</font>\n",
    "\n",
    "Uncomment the cell below if you are on Google Colab. Unfortunately this might no longer work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-get install libproj-dev proj-data proj-bin\n",
    "#!apt-get install libgeos-dev\n",
    "#!pip install cython\n",
    "#!pip install cartopy\n",
    "#!pip install netCDF4\n",
    "#!pip install xarray==0.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "print(\"Version of Xarray: \", xr.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Basic Manipulations</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Xarray DataArray</font>\n",
    "\n",
    "- Xarray’s implementation of a labeled, multi-dimensional array.\n",
    "- Has several key properties:\n",
    "    - `values`: a numpy.ndarray holding the array’s values\n",
    "    - `dims`: dimension names for each axis (e.g., `('x', 'y', 'z')`)\n",
    "    - `coords`: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)\n",
    "    - `attrs`: dict to hold arbitrary metadata (attributes)\n",
    "    \n",
    "- Xarray uses `dims` and `coords` to enable its core metadata aware operations. \n",
    "- Dimensions provide names that xarray uses instead of the `axis` argument found in many Numpy functions. \n",
    "- Coordinates enable fast label based indexing and alignment, building on the functionality of the `index` found on a Pandas `DataFrame` or `Series`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a DataArray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = [[11.0, 12.0, 13.0, 14.0, 15.0], \n",
    "             [21.0, 22.0, 23.0, 24.0, 25.0],\n",
    "             [31.0, 32.0, 33.0, 34.0, 35.0],\n",
    "             [41.0, 42.0, 43.0, 44.0, 45]]\n",
    "\n",
    "print(type(list_data))\n",
    "print(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.array(list_data)\n",
    "print(type(np_data))\n",
    "print(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data)\n",
    "print(type(xr_data))\n",
    "print(xr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a 2D array, assigned the names `x` and `y` to the two dimensions respectively and associated two coordinate labels `10`, `20`, `30` and `40` with the two locations along the `x` dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data, \n",
    "                       dims=(\"x\", \"y\"), \n",
    "                       coords={\"x\": [10, 20, 30, 40]})\n",
    "print(xr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract the properties of the DataArray.\n",
    "\n",
    "Get the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dimension labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values of the dimension `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data['x'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.x.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values of the dimension `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing**\n",
    "\n",
    "- Xarray supports four kinds of indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional and by integer label, like Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xr_data[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` or \"location\": positional and coordinate label, like Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.loc[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`isel` or \"integer select\":  by dimension name and integer label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.isel(x=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sel` or \"select\": by dimension name and coordinate label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(x=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlike positional indexing, label-based indexing frees us from having to know how our array is organized. \n",
    "- All we need to know are the dimension name and the label we wish to index i.e. `data.sel(x=30)` works regardless of whether `x` is the first or second dimension of the array and regardless of whether `30` is the first or second element of `x`. \n",
    "- We have already told xarray that `x` is the first dimension when we created data: Xarray keeps track of this so we don’t have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes\n",
    "\n",
    "- We can add metadata attributes that can be use later for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.attrs[\"long_name\"] = \"random temperature\"\n",
    "xr_data.attrs[\"units\"] = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add metadata to coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.x.attrs[\"units\"] = \"x units\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computations\n",
    "\n",
    "- DataArrays work similarly to Numpy arrays:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can scale and offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Numpy built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-0.25*xr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `where()` to conditionally switch between values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.where(xr_data > 33, '> 33', '< 33')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sum all the entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation operations can use dimension names instead of axis numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arithmetic operations broadcast are based on dimension name. \n",
    "- You don not need to insert dummy dimensions for alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xr.DataArray(np.random.random(5), [xr_data.coords[\"y\"]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = xr.DataArray(np.random.random(6), dims=\"z\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not need to worry about the order of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data - xr_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations also align based on index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data[:-1] - xr_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpolation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(x=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use a Pandas-like call to visualize the data.\n",
    "- The labeling is automatically done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Going to Pandas**\n",
    "\n",
    "Xarray objects can be easily converted to and from Pandas objects using the `to_series()`, `to_dataframe()` and `to_xarray()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series = xr_data.to_series()\n",
    "pd_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Xarray Datasets</font>\n",
    "\n",
    "- `xarray.Dataset` is a dict-like container of aligned DataArray objects. \n",
    "- It can be seen as a multi-dimensional generalization of the `pandas.DataFrame`.\n",
    "- Variables in datasets can have different `dtype` and even different dimensions.\n",
    "- All dimensions are assumed to refer to points in the same shared coordinate system:\n",
    "     - If two variables have dimension `x`, that dimension must be identical in both variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a dataset with three `DataArrays` named `da_1`, `da_2` and `da_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst = xr.Dataset({\"da_1\": xr_data, \n",
    "                     \"da_2\": (\"x\", [1, 2, 3, 4]), \n",
    "                     \"da_3\": np.pi})\n",
    "xr_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the dictionary or dot indexing to pull out `Dataset` variables as `DataArray` objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst[\"da_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray automatically aligns `da_2` with `DataArray` `da_1`: they share the same coordinate system so that `xr_dst.da_1['x'] == xr_dst.da_s['x'] == xr_dst['x']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_1.sel(x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_2.sel(x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the dataset in a netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.to_netcdf(\"sample_netcdf.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(\"sample_netcdf.nc\") as fid:\n",
    "     print(fid.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Manipulating a netCDF File</font> \n",
    "\n",
    "- We will manipulate NOAA NCEP Reanalysis data.\n",
    "- The reanalysis project uses an analysis/forecast system to perform data assimilation using past data from 1948 to the present.\n",
    "- Spatial coverage: 2.5 degree latitude x 2.5 degree longitude global grid (144x73).\n",
    "- It produces outputs 4 times per day.\n",
    "- Here, we will focus on surface air temperature for 2018: 4x365 = 1460 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995.2018.nc\"\n",
    "ds = xr.open_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_attribute = ds.attrs\n",
    "dts_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_attribute['References']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Work With the NetCDF Data Structure </font>\n",
    "\n",
    "- An Xarray contains metadata making it self-describing. \n",
    "- There are three dimensions to consider when working with this data which represent the x,y and z dimensions of the data: latitude/longitude/time.\n",
    "- This particular dataset contains global time series of surface air temperatures for 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the Air Temperature dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D = ds.air\n",
    "air_temp2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get latitude/longitude information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D['lat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D['lat'].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum/Maximum latidtude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The min and max latitude values in the data is:\", \n",
    "      air_temp2D['lat'].values.min(), air_temp2D['lat'].values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The min and max longitude values in the data is:\", \n",
    "      air_temp2D['lon'].values.min(), air_temp2D['lon'].values.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the time information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D[\"time\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The earliest date in the data is:\", air_temp2D[\"time\"].values.min())\n",
    "print(\"The latest   date in the data is:\", air_temp2D[\"time\"].values.max())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(air_temp2D[\"time\"].values))\n",
    "print(air_temp2D[\"time\"].values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self describing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = air_temp2D.attrs\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata['units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slicing the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single x, y combination from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 50\n",
    "longitude = air_temp2D[\"lon\"].values[key]\n",
    "latitude = air_temp2D[\"lat\"].values[key]\n",
    "\n",
    "print(\"Longitude = {} \\n Latitude = {}\".format(longitude, latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "ax = plt.axes(projection=map_projection)\n",
    "ax.stock_img()\n",
    "\n",
    "# Plot the selected location \n",
    "plt.plot([longitude], [latitude], 'r*', \n",
    "        transform=data_transform,\n",
    "        color=\"purple\", \n",
    "         markersize=10)\n",
    "\n",
    "ax.set(title=\"Location of the Latitude/Longitude Being Used to Slice Your netcdf Climate Data File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point = air_temp2D.sel(lat=latitude, lon=longitude)\n",
    "one_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you slice the data by a single point, the output data only has a single array of values. \n",
    "- The values represent air temperature (in K) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the first few values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time series plot at a single location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make the plot a bit prettier by using the Matplotlib plot parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "one_point.plot.line(hue='lat', marker=\"o\", ax=ax, color=\"grey\",\n",
    "                    markerfacecolor=\"purple\",\n",
    "                    markeredgecolor=\"purple\")\n",
    "ax.set(title=\"Time Series For a Single Lat/Lon Location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Slice the Data By Time and Location</font>\n",
    "- We want to slice the data at a selected lat/lon location and for the months of April to June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2018-04-01\"\n",
    "end_date = \"2018-06-30\"\n",
    "temp_apr_jun = air_temp2D.sel(time=slice(start_date, end_date),\n",
    "                            lat=latitude, lon=longitude)\n",
    "temp_apr_jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_apr_jun.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data just like you did above\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "temp_apr_jun.plot.line(hue='lat',marker=\"o\", ax=ax, color=\"grey\",\n",
    "                       markerfacecolor=\"purple\",\n",
    "                       markeredgecolor=\"purple\")\n",
    "ax.set(title=\"April-June Time Series of Temperature Data For A Single Location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Time series at specific latitudes and alon a longitude line</font>\n",
    "\n",
    "- We can use line plots to check the variation of air temperature at three different latitudes along a longitude line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D.isel(lon=10, lat=[19, 21, 22]).plot.line(x=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Slice The Data Across a Spatial Extent For A Specific Time Period</font>\n",
    "\n",
    "- We use `.sel()` combined with `slice()` to subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2018-04-01\"\n",
    "end_date = \"2018-04-01\"\n",
    "one_day_data = air_temp2D.sel(time=slice(start_date, end_date))\n",
    "one_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `.plot()` on the data, the default plot is a histogram representing the range of raster pixel values in your data for all time periods (3 months in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Spatial Plots</font>\n",
    "- If you want to plot the data spatially as a raster, you can use `.plot()` but specify the lon and lat values as the x and y dimensions to plot. \n",
    "- You can add the following parameters to your .plot() call to make sure each time step in your data plots spatially:\n",
    "    - `col_wrap=`: adjust how how many columns the each subplot is spread across \n",
    "    - `col=`: what dimension is being plotted in each subplot.\n",
    "\n",
    "Here, we want a single raster for each time record in the data so you specify `col='time'`. `col_wrap=2` forces the plots to be on two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.plot(x=\"lon\",\n",
    "                  y=\"lat\",\n",
    "                  col=\"time\",\n",
    "                  col_wrap=2)\n",
    "plt.suptitle(\"One day Air Temp\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can plot with Cartopy map projection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "aspect = one_day_data.shape[2] / one_day_data.shape[1]\n",
    "\n",
    "p = one_day_data.plot(transform=data_transform,  # the data's projection\n",
    "                      col='time', col_wrap=2,\n",
    "                      aspect=aspect,\n",
    "                      figsize=(10, 10),\n",
    "                      subplot_kws={'projection': map_projection})  # the plot's projection\n",
    "\n",
    "for ax in p.axes.flat:\n",
    "    ax.coastlines()\n",
    "    #ax.set_extent(extent)\n",
    "\n",
    "plt.suptitle(\"One day Air Temp\", y = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Cartopy only to do the countour plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "fig = plt.figure(tight_layout=False)\n",
    "nrows, ncols = 2, 2\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=map_projection)\n",
    "    one_day_data[i].plot()\n",
    "    ax.coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.util\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "fig = plt.figure(tight_layout=False)\n",
    "nrows, ncols = 2, 2\n",
    "#fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "#ax = axes.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=map_projection)\n",
    "    data = one_day_data[i].values\n",
    "    lats = one_day_data[i]['lat'].values\n",
    "    lons = one_day_data[i]['lon'].values\n",
    "\n",
    "    data, lons = cartopy.util.add_cyclic_point(data, coord=lons)\n",
    "    cp = plt.contourf(lons, lats, data, 60,\n",
    "                      cmap='jet', transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    title = f'Time = {str(one_day_data[i].time.values)[0:19]}'\n",
    "    ax.set_title(title)\n",
    "\n",
    "# add a subplot for vertical colorbar\n",
    "bottom, top = 0.1, 0.9\n",
    "left, right = 0.1, 0.8\n",
    "fig.subplots_adjust(top=top, bottom=bottom, \n",
    "                    left=left, right=right, hspace=0.15, wspace=0.25)\n",
    "cbar_ax = fig.add_axes([0.85, bottom, 0.05, top-bottom])\n",
    "fig.colorbar(cp, cax=cbar_ax)  # plot colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Perform Correlation Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the dataset by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_air_temp  = air_temp2D.groupby('time.month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_air_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the monthly climatologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_clim = grp_air_temp.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the anomaly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom = grp_air_temp - air_temp_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the anomaly for the first time record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot anomaly time series at a specific location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_ref = air_temp_anom.sel(lon=200, lat=0, method='nearest')\n",
    "air_temp_ref.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def corrrelation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_cor = corrrelation(air_temp_anom, air_temp_ref, dims='time')\n",
    "pc = air_temp_cor.plot()\n",
    "pc.axes.set_title('Correlation btw. global airTemp Anomaly and airTemp Anomaly at one point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the the time series spatial means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom_avg = air_temp_anom.mean(dim=['lat', 'lon'])\n",
    "air_temp_anom_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom_avg.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation using datetime strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inter_data = air_temp.interp(time=[\"2018-03-15\", \"2018-03-16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Manipulating 3D Field </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'https://downloads.psl.noaa.gov/Datasets/ncep.reanalysis.dailyavgs/pressure/air.2020.nc'\n",
    "fname = \"air_temp_2020.nc\"\n",
    "urllib.request.urlretrieve(url, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds = xr.open_dataset(fname)\n",
    "xds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the dimension values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.level.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.lat.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the 3D temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D = xds.air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plots at `600 mb`, `25.0` degree longitude and at three latitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600., lon=25.0).isel(lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if I what to do the same plot at longitude `24.5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600., lon=24.5).isel(lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform an interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600.).isel(lat=[19, 21, 22]).interp(lon=24.5).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_air_temp3D = air_temp3D.groupby('time.month').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_air_temp3D.sel(level='1000.0').plot(x=\"lon\", y=\"lat\",\n",
    "                                           col=\"month\",\n",
    "                                           col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Mean: Contour plot at each vertical level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.mean(dim='time').plot(x=\"lon\", y=\"lat\",\n",
    "                                           col=\"level\",\n",
    "                                           col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the Zonal Mean Height plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "air_temp3D.mean(dim='time').mean(dim='lon').plot(ax=ax, \n",
    "                                                 x='lat', \n",
    "                                                 y='level')\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Vertical Level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise</font>\n",
    "\n",
    "Modify the code shown in:\n",
    "\n",
    "[https://www.nccs.nasa.gov/nccs-users/instructional/adapt-instructional/python/xarray-generating-climatology-dataset-using-CMIP6](https://www.nccs.nasa.gov/nccs-users/instructional/adapt-instructional/python/xarray-generating-climatology-dataset-using-CMIP6)\n",
    "\n",
    "to reproduce the plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reading multiple netCDF Files</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.reanalysis/surface'\n",
    "byear = 2017\n",
    "eyear = 2019\n",
    "files = ['{0}/air.sig995.{1:04d}.nc'.format(url, years) for years in range(byear,eyear,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(files)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_airT = ds.air\n",
    "dst_airT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select data for a given time range:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2017 = dst_airT.sel(time=slice(\"2017-01-01\", \"2017-12-31\"))\n",
    "air_temp2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the daily means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dst = dst_airT.resample(time='1D').mean()\n",
    "daily_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plot at Greenbelt, MD location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_ref =  39.00\n",
    "lon_ref = -76.88\n",
    "daily_dst_ref = daily_dst.sel(lon=lon_ref, lat=lat_ref, method='nearest')\n",
    "daily_dst_ref.to_pandas().T.plot()\n",
    "units = dst_airT.attrs['units']\n",
    "plt.ylabel(f\"Air Temperature ({units})\")\n",
    "plt.title('Time series plot for Greenbelt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the monthly means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_dst = dst_airT.resample(time='1M').mean()\n",
    "monthly_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the annual means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dst = dst_airT.resample(time='1A').mean()\n",
    "yearly_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dst.plot(x=\"lon\", y=\"lat\",\n",
    "                col=\"time\", col_wrap=2)\n",
    "plt.suptitle(\"Yearly Means\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute seasonal values:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seasons `JFM`, `AMJ`, `JAS` and `OND`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFM_dst = dst_airT.resample(time='QS-JAN').mean()\n",
    "JFM_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFM_dst.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=3)\n",
    "plt.suptitle(\"Seasonal Means (JFM, AMJ, JAS, OND)\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seasons `DJF`, `MAM`, `JJA` and `SON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst = dst_airT.resample(time='QS-DEC').mean()\n",
    "DJF_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use the following for the seasons `DJF`, `MAM`, `JJA`, `SON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst2 = dst_airT.groupby('time.season').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=3)\n",
    "plt.suptitle(\"Seasonal Means (DJF, MAM, JJA, SON)\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Using `Pandas DataFrames`</font> \n",
    "\n",
    "- We use web scrapping to access the <a href=\"https://neo.sci.gsfc.nasa.gov/\">NASA Earth Observations (NEO)</a> website to obtain the AOT measurements for a given range of days (from 2000 to present).\n",
    "- For each daily reading, we create a `Pandas DataFrame` that is use to create a `Xarray DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as reqs\n",
    "from bs4 import BeautifulSoup as bso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the day range of interest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = '2019-01-01'\n",
    "end_date = '2019-12-21'\n",
    "\n",
    "datasetID = 'MODAL2_M_AER_OD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(beg_date, end_date, freq='D'):\n",
    "    \"\"\"\n",
    "      Create a list containing all the dates between\n",
    "      beg_date and end_date.\n",
    "      \n",
    "      Input parameters:\n",
    "         - beg_date: (str) start date in the format YYYY-MM-DD\n",
    "         - end_date: (str) end   date in the format YYYY-MM-DD\n",
    "         - freq: (str) frequency - 'D' for days and 'M' for months\n",
    "      Returned value:\n",
    "         - a list of dates in the format YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    pd_series = pd.date_range(start=beg_date, end=end_date, freq=freq)\n",
    "    list_dates = [dt.strftime('%Y-%m-%d') for dt in pd_series]\n",
    "    return list_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls(datasetID, list_dates):\n",
    "    \"\"\"\n",
    "      Create a list containing the urls for the websites we\n",
    "      want to access to grab the full addresses of the CVS files\n",
    "      (that have the mesurements).\n",
    "      \n",
    "      Input parameters:\n",
    "         - datasetID: (str) dataset identifier for the data of interest\n",
    "         - list_dates: (list) list of dates of interest\n",
    "      Returned value:\n",
    "         - a list of urls\n",
    "    \"\"\"\n",
    "    url = 'https://neo.sci.gsfc.nasa.gov/view.php?datasetId='\n",
    "    url_base = url+datasetID+'&year='\n",
    "    list_urls = [url_base+dt for dt in list_dates]\n",
    "    return list_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_dates(beg_date, end_date, freq='D')\n",
    "urls = generate_urls(datasetID, dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse each website to obtain the location of the CSV files (conatining measurements):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_urls = list()\n",
    "for url in urls:\n",
    "    source = reqs.get(url)\n",
    "    mysoup = bso(source.text, 'html.parser')\n",
    "    href_tags = mysoup.find_all(href=True)\n",
    "    for tag in href_tags:\n",
    "        loc_url = tag[\"href\"]\n",
    "        if \"CSV\" in loc_url:\n",
    "            csv_urls.append(loc_url)\n",
    "            break\n",
    "\n",
    "print(len(csv_urls), len(urls), len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read all the CSV files and create a Xarray DataSet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = list()\n",
    "dts = list()\n",
    "for i, csv_file in enumerate(csv_urls):\n",
    "    dts.append(pd.to_datetime(dates[i]))\n",
    "        \n",
    "    df = pd.read_csv(csv_file, index_col=0, na_values=99999.0)\n",
    "    da = xr.DataArray(df.values, \n",
    "                      coords=[[float(lat) for lat in df.index], \n",
    "                              [float(lon) for lon in df.columns]],\n",
    "                      dims=['latitude', 'longitude'])\n",
    "    \n",
    "    das.append(da)\n",
    "\n",
    "xr_dst = xr.concat(das, pd.Index(dts, name='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thirty days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtydays = xr_dst[0:31]\n",
    "thirtydays.plot(x=\"longitude\", y=\"latitude\",\n",
    "                col=\"date\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average over the first thirty days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtydays.mean(dim='date').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in over the USA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = thirtydays.sel(latitude=slice(50.05, 20.05),\n",
    "                 longitude=slice(-125.05, -66.50))\n",
    "usa.mean(dim='date').plot(cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax_p = plt.gca(projection=ccrs.LambertConformal(), aspect='auto')\n",
    "ax_p.coastlines()\n",
    "ax_p.set_extent([-125.05, -66.50, 20.05, 50.05])\n",
    "usa.mean(dim='date').plot.imshow(ax=ax_p, cmap='RdBu_r', \n",
    "                                 transform=ccrs.PlateCarree());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_means = xr_dst.groupby(xr_dst.date.dt.month).mean(dim='date')\n",
    "monthly_means.plot(x='longitude', y='latitude', col='month', \n",
    "                   cmap='RdBu_r', col_wrap=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.mean(dim='date').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise</font>\n",
    "\n",
    "The website \n",
    "\n",
    "[https://neo.sci.gsfc.nasa.gov/](https://neo.sci.gsfc.nasa.gov/)\n",
    "\n",
    "also contains measurements for:\n",
    "\n",
    "- Carbon Monoxide (`MOP_CO_M`)\n",
    "- Cloud optical Thickness (`MODAL2_M_CLD_OT`)\n",
    "- Cloud Fraction (`MODAL2_M_CLD_FR`)\n",
    "- etc.\n",
    "\n",
    "Select one of them and retrieve dataset for a a given time period. You may want to first verify the raange of dates where the measurements are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Accessing HDF5 Files</font>\n",
    "\n",
    "We can only access data within groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the hdf5-file using netCDF4 in diskless non-persistence mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/astg606/py_materials/master/xarray/sample_hdf5.h5\"\n",
    "hdf5_fname = \"sample_hdf5.h5\"\n",
    "urllib.request.urlretrieve(url, hdf5_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf = nc4.Dataset(hdf5_fname, diskless=True, persist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the file contents including `groups`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ncf.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make use of `xarray.backends.NetCDF4DataStore` to open the wanted hdf5-groups (Xarray can only get hold of one hdf5-group at a time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_group_name = '3D_Data'\n",
    "nch = ncf.groups.get(hdf5_group_name)\n",
    "xds = xr.open_dataset(xr.backends.NetCDF4DataStore(nch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will give you a dataset `xds` with all attributes and variables (datasets) of the group hdf5-name. \n",
    "- Note that you will not get access to sub-groups. \n",
    "- You would need to claim subgroups by the same mechanism. \n",
    "- If you want to apply Dask, you would need to add the keyword chunking with wanted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = xds.temp\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.isel(phony_dim_3=1, phony_dim_4=2).plot(x=\"phony_dim_6\", \n",
    "                                             y=\"phony_dim_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoding data\n",
    "\n",
    "- There is no (real) automatism for decoding data like this could be done for NetCDF files. \n",
    "- If you have a integer compressed 2d variable (dataset) `var` with some attributes `gain` and `offset` you can add the NetCDF specific attributes `scale_factor` and `add_offset` to the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = ''\n",
    "var = xds[var_name]\n",
    "var.attrs['scale_factor'] = var.attrs.get('gain')\n",
    "var.attrs['add_offset'] = var.attrs.get('offset')\n",
    "ds = xarray.decode_cf(xds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will decode your variable using netcdf mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You could try to give the extracted dimension useful names (you will get something like phony_dim_0, phony_dim_1, ..., phony_dim_N) and assign new (as in example) or existing variables/coordinates to those dimensions to gain as much of the xarray machinery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = xds[var_name]\n",
    "var.attrs['scale_factor'] = var.attrs.get('gain')\n",
    "var.attrs['add_offset'] = var.attrs.get('offset')\n",
    "dims = var.dims\n",
    "xds[var_name] = var.rename({dims[0]: 'x', dims[1]: 'y'})\n",
    "xds = xds.assign({'x': (['x'], xvals, xattrs)})\n",
    "xds = xds.assign({'y': (['y'], yvals, yattrs)})\n",
    "ds = xarray.decode_cf(xds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
